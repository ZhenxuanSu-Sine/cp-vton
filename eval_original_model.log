Namespace(batch_size=4, checkpoint='checkpoints/gmm_train_new/gmm_final.pth', data_list='test_pairs.txt', datamode='test', dataroot='/mnt/nas/dataset_share/VITON/data/', display_count=1, fine_height=256, fine_width=192, gpu_ids='', grid_size=5, name='gmm_train_new', radius=5, result_dir='result', shuffle=False, stage='GMM', tensorboard_dir='tensorboard', workers=4)
Start to test stage: GMM, named: gmm_train_new!
initialization method [normal]
initialization method [normal]
step:        1, time: 1.076, L1_loss: 0.166626
step:        2, time: 0.632, L1_loss: 0.184714
step:        3, time: 0.516, L1_loss: 0.216636
step:        4, time: 0.553, L1_loss: 0.159924
step:        5, time: 0.528, L1_loss: 0.291733
step:        6, time: 0.538, L1_loss: 0.138498
step:        7, time: 0.460, L1_loss: 0.260450
step:        8, time: 0.485, L1_loss: 0.145828
step:        9, time: 0.512, L1_loss: 0.181810
step:       10, time: 0.943, L1_loss: 0.262514
step:       11, time: 0.547, L1_loss: 0.137722
step:       12, time: 0.598, L1_loss: 0.149690
step:       13, time: 0.535, L1_loss: 0.168481
step:       14, time: 0.544, L1_loss: 0.155364
step:       15, time: 0.516, L1_loss: 0.266199
step:       16, time: 0.502, L1_loss: 0.323014
step:       17, time: 0.471, L1_loss: 0.286880
step:       18, time: 0.473, L1_loss: 0.245740
step:       19, time: 0.484, L1_loss: 0.114444
step:       20, time: 0.500, L1_loss: 0.227273
step:       21, time: 0.483, L1_loss: 0.169142
step:       22, time: 0.525, L1_loss: 0.372750
step:       23, time: 0.471, L1_loss: 0.194352
step:       24, time: 0.476, L1_loss: 0.198046
step:       25, time: 0.511, L1_loss: 0.145152
step:       26, time: 0.484, L1_loss: 0.215621
step:       27, time: 0.512, L1_loss: 0.153003
step:       28, time: 0.528, L1_loss: 0.215592
step:       29, time: 0.527, L1_loss: 0.174552
step:       30, time: 0.509, L1_loss: 0.198273
step:       31, time: 0.532, L1_loss: 0.253484
step:       32, time: 0.512, L1_loss: 0.183249
step:       33, time: 0.529, L1_loss: 0.141145
step:       34, time: 0.504, L1_loss: 0.123007
step:       35, time: 0.490, L1_loss: 0.222051
step:       36, time: 0.537, L1_loss: 0.228957
step:       37, time: 0.537, L1_loss: 0.192452
step:       38, time: 0.586, L1_loss: 0.221966
step:       39, time: 0.483, L1_loss: 0.214423
step:       40, time: 0.514, L1_loss: 0.229386
step:       41, time: 0.479, L1_loss: 0.145453
step:       42, time: 0.558, L1_loss: 0.230851
step:       43, time: 0.549, L1_loss: 0.181976
step:       44, time: 0.557, L1_loss: 0.182894
step:       45, time: 0.350, L1_loss: 0.241188
step:       46, time: 0.890, L1_loss: 0.214979
step:       47, time: 0.514, L1_loss: 0.256788
step:       48, time: 0.529, L1_loss: 0.232472
step:       49, time: 0.572, L1_loss: 0.160230
step:       50, time: 0.534, L1_loss: 0.182798
step:       51, time: 0.498, L1_loss: 0.120536
step:       52, time: 0.530, L1_loss: 0.154609
step:       53, time: 0.527, L1_loss: 0.187991
step:       54, time: 0.436, L1_loss: 0.218351
step:       55, time: 0.508, L1_loss: 0.179796
step:       56, time: 0.543, L1_loss: 0.278736
step:       57, time: 0.544, L1_loss: 0.425396
step:       58, time: 0.546, L1_loss: 0.267027
step:       59, time: 0.598, L1_loss: 0.217907
step:       60, time: 0.540, L1_loss: 0.223561
step:       61, time: 0.627, L1_loss: 0.257312
step:       62, time: 0.572, L1_loss: 0.164882
step:       63, time: 0.508, L1_loss: 0.209061
step:       64, time: 0.545, L1_loss: 0.232433
step:       65, time: 0.530, L1_loss: 0.245353
step:       66, time: 0.544, L1_loss: 0.248907
step:       67, time: 0.519, L1_loss: 0.156379
step:       68, time: 0.515, L1_loss: 0.182543
step:       69, time: 0.501, L1_loss: 0.248672
step:       70, time: 0.492, L1_loss: 0.202024
step:       71, time: 0.547, L1_loss: 0.197925
step:       72, time: 0.484, L1_loss: 0.168995
step:       73, time: 0.524, L1_loss: 0.400550
step:       74, time: 0.547, L1_loss: 0.217885
step:       75, time: 0.579, L1_loss: 0.137497
step:       76, time: 0.564, L1_loss: 0.173818
step:       77, time: 0.553, L1_loss: 0.184921
step:       78, time: 0.578, L1_loss: 0.262050
step:       79, time: 0.476, L1_loss: 0.143931
step:       80, time: 0.863, L1_loss: 0.242394
step:       81, time: 0.512, L1_loss: 0.182393
step:       82, time: 0.505, L1_loss: 0.211727
step:       83, time: 0.518, L1_loss: 0.321051
step:       84, time: 0.616, L1_loss: 0.191975
step:       85, time: 0.548, L1_loss: 0.274749
step:       86, time: 0.516, L1_loss: 0.365811
step:       87, time: 0.496, L1_loss: 0.285319
step:       88, time: 0.553, L1_loss: 0.149906
step:       89, time: 0.551, L1_loss: 0.087343
step:       90, time: 0.579, L1_loss: 0.181576
step:       91, time: 0.546, L1_loss: 0.234742
step:       92, time: 0.464, L1_loss: 0.162642
step:       93, time: 0.541, L1_loss: 0.159348
step:       94, time: 0.548, L1_loss: 0.138861
step:       95, time: 0.535, L1_loss: 0.150523
step:       96, time: 0.526, L1_loss: 0.184616
step:       97, time: 0.516, L1_loss: 0.332950
step:       98, time: 0.510, L1_loss: 0.075805
step:       99, time: 0.522, L1_loss: 0.142944
step:      100, time: 0.517, L1_loss: 0.090896
step:      101, time: 0.509, L1_loss: 0.131896
step:      102, time: 0.460, L1_loss: 0.134949
step:      103, time: 0.517, L1_loss: 0.275407
step:      104, time: 0.552, L1_loss: 0.349713
step:      105, time: 0.533, L1_loss: 0.144723
step:      106, time: 0.525, L1_loss: 0.167259
step:      107, time: 0.516, L1_loss: 0.259991
step:      108, time: 0.604, L1_loss: 0.105439
step:      109, time: 0.522, L1_loss: 0.253870
step:      110, time: 0.579, L1_loss: 0.344551
step:      111, time: 0.560, L1_loss: 0.152305
step:      112, time: 0.622, L1_loss: 0.210923
step:      113, time: 0.489, L1_loss: 0.278342
step:      114, time: 0.461, L1_loss: 0.202924
step:      115, time: 0.417, L1_loss: 0.314569
step:      116, time: 0.511, L1_loss: 0.335427
step:      117, time: 0.485, L1_loss: 0.248035
step:      118, time: 0.461, L1_loss: 0.187415
step:      119, time: 0.504, L1_loss: 0.153632
step:      120, time: 0.514, L1_loss: 0.190744
step:      121, time: 0.518, L1_loss: 0.155783
step:      122, time: 0.587, L1_loss: 0.214190
step:      123, time: 0.516, L1_loss: 0.134936
step:      124, time: 0.515, L1_loss: 0.243086
step:      125, time: 0.534, L1_loss: 0.145448
step:      126, time: 0.491, L1_loss: 0.120852
step:      127, time: 0.489, L1_loss: 0.184000
step:      128, time: 0.470, L1_loss: 0.119388
step:      129, time: 0.457, L1_loss: 0.167900
step:      130, time: 0.515, L1_loss: 0.108449
step:      131, time: 0.473, L1_loss: 0.117658
step:      132, time: 0.497, L1_loss: 0.192919
step:      133, time: 0.509, L1_loss: 0.274085
step:      134, time: 0.495, L1_loss: 0.296387
step:      135, time: 0.556, L1_loss: 0.170735
step:      136, time: 0.541, L1_loss: 0.203292
step:      137, time: 0.532, L1_loss: 0.250265
step:      138, time: 0.488, L1_loss: 0.195345
step:      139, time: 0.486, L1_loss: 0.181146
step:      140, time: 0.510, L1_loss: 0.249578
step:      141, time: 1.052, L1_loss: 0.149005
step:      142, time: 0.511, L1_loss: 0.161162
step:      143, time: 0.533, L1_loss: 0.240519
step:      144, time: 0.517, L1_loss: 0.133103
step:      145, time: 0.530, L1_loss: 0.273827
step:      146, time: 0.523, L1_loss: 0.191337
step:      147, time: 0.509, L1_loss: 0.241200
step:      148, time: 0.506, L1_loss: 0.231598
step:      149, time: 0.534, L1_loss: 0.143456
step:      150, time: 0.515, L1_loss: 0.117888
step:      151, time: 0.510, L1_loss: 0.263389
step:      152, time: 0.501, L1_loss: 0.160593
step:      153, time: 0.549, L1_loss: 0.197462
step:      154, time: 0.465, L1_loss: 0.178262
step:      155, time: 0.465, L1_loss: 0.219581
step:      156, time: 0.516, L1_loss: 0.183908
step:      157, time: 0.539, L1_loss: 0.283766
step:      158, time: 0.463, L1_loss: 0.202203
step:      159, time: 0.504, L1_loss: 0.113751
step:      160, time: 0.520, L1_loss: 0.086098
step:      161, time: 0.538, L1_loss: 0.145112
step:      162, time: 0.504, L1_loss: 0.200936
step:      163, time: 0.565, L1_loss: 0.153819
step:      164, time: 0.541, L1_loss: 0.149746
step:      165, time: 0.528, L1_loss: 0.236894
step:      166, time: 0.491, L1_loss: 0.142275
step:      167, time: 0.543, L1_loss: 0.179790
step:      168, time: 0.499, L1_loss: 0.168098
step:      169, time: 2.279, L1_loss: 0.191204
step:      170, time: 0.573, L1_loss: 0.216124
step:      171, time: 0.544, L1_loss: 0.190643
step:      172, time: 0.613, L1_loss: 0.175329
step:      173, time: 0.511, L1_loss: 0.232900
step:      174, time: 0.516, L1_loss: 0.162650
step:      175, time: 0.466, L1_loss: 0.212361
step:      176, time: 0.490, L1_loss: 0.240694
step:      177, time: 0.500, L1_loss: 0.099031
step:      178, time: 0.507, L1_loss: 0.181214
step:      179, time: 0.510, L1_loss: 0.125374
step:      180, time: 0.511, L1_loss: 0.235385
step:      181, time: 0.549, L1_loss: 0.223253
step:      182, time: 0.549, L1_loss: 0.255217
step:      183, time: 0.547, L1_loss: 0.198344
step:      184, time: 0.492, L1_loss: 0.217909
step:      185, time: 0.489, L1_loss: 0.162142
step:      186, time: 0.521, L1_loss: 0.166111
step:      187, time: 0.517, L1_loss: 0.195428
step:      188, time: 0.498, L1_loss: 0.236562
step:      189, time: 0.527, L1_loss: 0.254359
step:      190, time: 0.487, L1_loss: 0.154740
step:      191, time: 0.514, L1_loss: 0.112741
step:      192, time: 0.517, L1_loss: 0.086959
step:      193, time: 0.522, L1_loss: 0.201875
step:      194, time: 0.525, L1_loss: 0.223731
step:      195, time: 0.494, L1_loss: 0.156406
step:      196, time: 0.524, L1_loss: 0.343067
step:      197, time: 0.587, L1_loss: 0.266409
step:      198, time: 0.513, L1_loss: 0.152649
step:      199, time: 0.540, L1_loss: 0.189316
step:      200, time: 0.525, L1_loss: 0.175286
step:      201, time: 0.528, L1_loss: 0.174984
step:      202, time: 1.095, L1_loss: 0.185492
step:      203, time: 0.516, L1_loss: 0.159011
step:      204, time: 0.500, L1_loss: 0.217048
step:      205, time: 0.500, L1_loss: 0.209082
step:      206, time: 0.557, L1_loss: 0.239674
step:      207, time: 0.577, L1_loss: 0.193552
step:      208, time: 0.492, L1_loss: 0.163363
step:      209, time: 0.542, L1_loss: 0.310441
step:      210, time: 0.565, L1_loss: 0.273768
step:      211, time: 0.533, L1_loss: 0.090198
step:      212, time: 0.497, L1_loss: 0.251470
step:      213, time: 0.562, L1_loss: 0.206417
step:      214, time: 0.478, L1_loss: 0.254083
step:      215, time: 0.520, L1_loss: 0.308884
step:      216, time: 0.453, L1_loss: 0.180229
step:      217, time: 0.451, L1_loss: 0.270807
step:      218, time: 0.444, L1_loss: 0.149072
step:      219, time: 0.508, L1_loss: 0.196119
step:      220, time: 0.483, L1_loss: 0.207780
step:      221, time: 0.426, L1_loss: 0.242745
step:      222, time: 0.524, L1_loss: 0.228165
step:      223, time: 0.496, L1_loss: 0.152691
step:      224, time: 0.511, L1_loss: 0.218708
step:      225, time: 0.513, L1_loss: 0.162614
step:      226, time: 0.475, L1_loss: 0.176690
step:      227, time: 0.475, L1_loss: 0.179174
step:      228, time: 0.490, L1_loss: 0.255148
step:      229, time: 1.175, L1_loss: 0.205614
step:      230, time: 0.576, L1_loss: 0.160169
step:      231, time: 0.639, L1_loss: 0.150990
step:      232, time: 0.509, L1_loss: 0.172011
step:      233, time: 0.501, L1_loss: 0.246083
step:      234, time: 0.507, L1_loss: 0.178550
step:      235, time: 0.509, L1_loss: 0.227220
step:      236, time: 0.539, L1_loss: 0.135680
step:      237, time: 0.538, L1_loss: 0.212627
step:      238, time: 0.464, L1_loss: 0.140068
step:      239, time: 0.505, L1_loss: 0.247258
step:      240, time: 0.504, L1_loss: 0.159734
step:      241, time: 0.519, L1_loss: 0.209513
step:      242, time: 0.501, L1_loss: 0.142814
step:      243, time: 0.506, L1_loss: 0.123576
step:      244, time: 0.526, L1_loss: 0.236815
step:      245, time: 0.526, L1_loss: 0.250589
step:      246, time: 0.514, L1_loss: 0.175287
step:      247, time: 1.575, L1_loss: 0.214874
step:      248, time: 0.585, L1_loss: 0.383784
step:      249, time: 0.532, L1_loss: 0.208118
step:      250, time: 0.530, L1_loss: 0.233470
step:      251, time: 0.502, L1_loss: 0.204146
step:      252, time: 0.472, L1_loss: 0.201980
step:      253, time: 0.499, L1_loss: 0.267419
step:      254, time: 0.479, L1_loss: 0.136505
step:      255, time: 1.018, L1_loss: 0.086866
step:      256, time: 0.501, L1_loss: 0.208337
step:      257, time: 0.508, L1_loss: 0.223854
step:      258, time: 0.513, L1_loss: 0.213292
step:      259, time: 0.472, L1_loss: 0.245268
step:      260, time: 0.489, L1_loss: 0.212164
step:      261, time: 0.497, L1_loss: 0.266893
step:      262, time: 0.448, L1_loss: 0.202838
step:      263, time: 0.483, L1_loss: 0.117299
step:      264, time: 0.542, L1_loss: 0.134115
step:      265, time: 0.495, L1_loss: 0.194444
step:      266, time: 0.533, L1_loss: 0.180083
step:      267, time: 0.540, L1_loss: 0.240371
step:      268, time: 0.508, L1_loss: 0.178046
step:      269, time: 0.568, L1_loss: 0.195866
step:      270, time: 0.564, L1_loss: 0.197209
step:      271, time: 0.464, L1_loss: 0.215033
step:      272, time: 0.488, L1_loss: 0.224678
step:      273, time: 0.460, L1_loss: 0.225276
step:      274, time: 0.512, L1_loss: 0.188424
step:      275, time: 0.522, L1_loss: 0.200421
step:      276, time: 0.517, L1_loss: 0.234926
step:      277, time: 0.539, L1_loss: 0.243497
step:      278, time: 0.507, L1_loss: 0.175547
step:      279, time: 0.503, L1_loss: 0.192651
step:      280, time: 0.486, L1_loss: 0.167223
step:      281, time: 0.530, L1_loss: 0.257301
step:      282, time: 0.519, L1_loss: 0.237067
step:      283, time: 0.535, L1_loss: 0.233152
step:      284, time: 0.461, L1_loss: 0.151247
step:      285, time: 0.538, L1_loss: 0.148334
step:      286, time: 0.512, L1_loss: 0.178623
step:      287, time: 0.512, L1_loss: 0.178842
step:      288, time: 0.506, L1_loss: 0.241092
step:      289, time: 0.538, L1_loss: 0.260447
step:      290, time: 0.387, L1_loss: 0.262051
step:      291, time: 0.975, L1_loss: 0.227833
step:      292, time: 0.576, L1_loss: 0.155956
step:      293, time: 0.513, L1_loss: 0.272503
step:      294, time: 0.542, L1_loss: 0.254027
step:      295, time: 0.564, L1_loss: 0.162352
step:      296, time: 0.580, L1_loss: 0.225470
step:      297, time: 0.483, L1_loss: 0.184276
step:      298, time: 0.543, L1_loss: 0.174189
step:      299, time: 0.525, L1_loss: 0.184459
step:      300, time: 0.531, L1_loss: 0.142800
step:      301, time: 0.537, L1_loss: 0.273723
step:      302, time: 0.525, L1_loss: 0.197234
step:      303, time: 0.527, L1_loss: 0.202479
step:      304, time: 0.585, L1_loss: 0.278277
step:      305, time: 0.537, L1_loss: 0.087614
step:      306, time: 0.514, L1_loss: 0.187063
step:      307, time: 0.507, L1_loss: 0.223192
step:      308, time: 0.582, L1_loss: 0.198287
step:      309, time: 0.470, L1_loss: 0.167050
step:      310, time: 0.518, L1_loss: 0.264600
step:      311, time: 0.536, L1_loss: 0.232020
step:      312, time: 0.533, L1_loss: 0.164666
step:      313, time: 0.534, L1_loss: 0.185326
step:      314, time: 0.497, L1_loss: 0.164360
step:      315, time: 0.540, L1_loss: 0.198001
step:      316, time: 0.495, L1_loss: 0.242085
step:      317, time: 1.087, L1_loss: 0.306920
step:      318, time: 0.551, L1_loss: 0.232243
step:      319, time: 0.522, L1_loss: 0.195286
step:      320, time: 0.537, L1_loss: 0.204803
step:      321, time: 0.521, L1_loss: 0.223419
step:      322, time: 0.488, L1_loss: 0.161303
step:      323, time: 0.499, L1_loss: 0.136812
step:      324, time: 0.530, L1_loss: 0.196884
step:      325, time: 0.539, L1_loss: 0.247690
step:      326, time: 0.486, L1_loss: 0.207051
step:      327, time: 0.513, L1_loss: 0.240819
step:      328, time: 0.496, L1_loss: 0.189872
step:      329, time: 0.518, L1_loss: 0.225592
step:      330, time: 0.514, L1_loss: 0.166334
step:      331, time: 0.511, L1_loss: 0.182360
step:      332, time: 0.553, L1_loss: 0.138547
step:      333, time: 0.546, L1_loss: 0.275793
step:      334, time: 0.538, L1_loss: 0.224451
step:      335, time: 0.495, L1_loss: 0.168545
step:      336, time: 0.534, L1_loss: 0.272725
step:      337, time: 0.555, L1_loss: 0.285099
step:      338, time: 0.527, L1_loss: 0.193096
step:      339, time: 0.486, L1_loss: 0.308983
step:      340, time: 0.514, L1_loss: 0.258459
step:      341, time: 0.561, L1_loss: 0.237061
step:      342, time: 0.551, L1_loss: 0.392653
step:      343, time: 0.527, L1_loss: 0.182365
step:      344, time: 0.397, L1_loss: 0.250941
step:      345, time: 0.705, L1_loss: 0.145424
step:      346, time: 0.515, L1_loss: 0.239973
step:      347, time: 0.546, L1_loss: 0.193391
step:      348, time: 0.567, L1_loss: 0.286825
step:      349, time: 0.535, L1_loss: 0.246482
step:      350, time: 0.470, L1_loss: 0.217769
step:      351, time: 0.519, L1_loss: 0.135249
step:      352, time: 0.511, L1_loss: 0.289668
step:      353, time: 0.550, L1_loss: 0.101307
step:      354, time: 0.519, L1_loss: 0.264434
step:      355, time: 0.494, L1_loss: 0.121858
step:      356, time: 0.522, L1_loss: 0.202039
step:      357, time: 0.549, L1_loss: 0.212334
step:      358, time: 0.567, L1_loss: 0.232837
step:      359, time: 0.514, L1_loss: 0.202637
step:      360, time: 0.504, L1_loss: 0.165371
step:      361, time: 0.486, L1_loss: 0.181825
step:      362, time: 0.567, L1_loss: 0.292062
step:      363, time: 0.538, L1_loss: 0.247629
step:      364, time: 0.481, L1_loss: 0.165622
step:      365, time: 0.514, L1_loss: 0.200995
step:      366, time: 0.519, L1_loss: 0.295257
step:      367, time: 0.506, L1_loss: 0.128814
step:      368, time: 0.511, L1_loss: 0.214244
step:      369, time: 0.532, L1_loss: 0.177426
step:      370, time: 0.339, L1_loss: 0.141421
step:      371, time: 0.685, L1_loss: 0.252652
step:      372, time: 0.517, L1_loss: 0.207863
step:      373, time: 0.455, L1_loss: 0.308711
step:      374, time: 0.479, L1_loss: 0.270058
step:      375, time: 0.458, L1_loss: 0.198655
step:      376, time: 0.497, L1_loss: 0.205126
step:      377, time: 0.485, L1_loss: 0.124120
step:      378, time: 0.553, L1_loss: 0.212508
step:      379, time: 0.585, L1_loss: 0.287110
step:      380, time: 0.557, L1_loss: 0.120828
step:      381, time: 0.528, L1_loss: 0.252185
step:      382, time: 0.589, L1_loss: 0.279362
step:      383, time: 0.482, L1_loss: 0.225327
step:      384, time: 0.486, L1_loss: 0.210120
step:      385, time: 0.508, L1_loss: 0.112264
step:      386, time: 0.493, L1_loss: 0.154204
step:      387, time: 0.526, L1_loss: 0.172875
step:      388, time: 0.503, L1_loss: 0.172496
step:      389, time: 0.562, L1_loss: 0.172564
step:      390, time: 0.584, L1_loss: 0.398620
step:      391, time: 0.581, L1_loss: 0.172072
step:      392, time: 0.550, L1_loss: 0.151434
step:      393, time: 0.520, L1_loss: 0.155109
step:      394, time: 0.492, L1_loss: 0.156024
step:      395, time: 0.545, L1_loss: 0.152801
step:      396, time: 0.444, L1_loss: 0.212762
step:      397, time: 0.801, L1_loss: 0.226080
step:      398, time: 0.501, L1_loss: 0.212898
step:      399, time: 0.540, L1_loss: 0.179103
step:      400, time: 0.542, L1_loss: 0.293551
step:      401, time: 0.587, L1_loss: 0.173880
step:      402, time: 0.521, L1_loss: 0.164865
step:      403, time: 0.542, L1_loss: 0.170662
step:      404, time: 0.490, L1_loss: 0.183709
step:      405, time: 0.512, L1_loss: 0.210067
step:      406, time: 0.531, L1_loss: 0.204304
step:      407, time: 0.520, L1_loss: 0.188103
step:      408, time: 0.487, L1_loss: 0.127784
step:      409, time: 0.507, L1_loss: 0.199997
step:      410, time: 0.541, L1_loss: 0.191435
step:      411, time: 0.559, L1_loss: 0.158974
step:      412, time: 0.559, L1_loss: 0.237493
step:      413, time: 0.525, L1_loss: 0.194770
step:      414, time: 0.529, L1_loss: 0.218405
step:      415, time: 0.534, L1_loss: 0.203582
step:      416, time: 0.497, L1_loss: 0.129230
step:      417, time: 0.548, L1_loss: 0.142118
step:      418, time: 0.527, L1_loss: 0.191608
step:      419, time: 0.517, L1_loss: 0.204974
step:      420, time: 0.520, L1_loss: 0.215123
step:      421, time: 0.529, L1_loss: 0.211335
step:      422, time: 0.610, L1_loss: 0.325928
step:      423, time: 0.513, L1_loss: 0.243048
step:      424, time: 0.491, L1_loss: 0.183421
step:      425, time: 0.528, L1_loss: 0.229957
step:      426, time: 0.525, L1_loss: 0.201561
step:      427, time: 0.502, L1_loss: 0.139806
step:      428, time: 0.508, L1_loss: 0.141332
step:      429, time: 0.543, L1_loss: 0.206659
step:      430, time: 0.488, L1_loss: 0.133322
step:      431, time: 0.511, L1_loss: 0.303524
step:      432, time: 0.488, L1_loss: 0.150613
step:      433, time: 0.543, L1_loss: 0.214829
step:      434, time: 0.485, L1_loss: 0.208120
step:      435, time: 0.476, L1_loss: 0.212067
step:      436, time: 0.496, L1_loss: 0.176809
step:      437, time: 0.496, L1_loss: 0.198675
step:      438, time: 0.564, L1_loss: 0.233788
step:      439, time: 0.539, L1_loss: 0.294892
step:      440, time: 0.504, L1_loss: 0.224210
step:      441, time: 0.507, L1_loss: 0.196439
step:      442, time: 0.509, L1_loss: 0.322448
step:      443, time: 0.480, L1_loss: 0.108402
step:      444, time: 0.541, L1_loss: 0.320346
step:      445, time: 0.541, L1_loss: 0.177030
step:      446, time: 0.510, L1_loss: 0.260067
step:      447, time: 0.547, L1_loss: 0.236248
step:      448, time: 0.455, L1_loss: 0.183526
step:      449, time: 0.484, L1_loss: 0.190887
step:      450, time: 0.522, L1_loss: 0.218850
step:      451, time: 0.591, L1_loss: 0.176873
step:      452, time: 0.545, L1_loss: 0.310026
step:      453, time: 0.501, L1_loss: 0.201890
step:      454, time: 0.464, L1_loss: 0.123498
step:      455, time: 1.185, L1_loss: 0.207323
step:      456, time: 0.527, L1_loss: 0.302484
step:      457, time: 0.570, L1_loss: 0.178010
step:      458, time: 0.513, L1_loss: 0.215824
step:      459, time: 0.560, L1_loss: 0.228039
step:      460, time: 0.539, L1_loss: 0.286821
step:      461, time: 0.566, L1_loss: 0.221027
step:      462, time: 0.562, L1_loss: 0.240907
step:      463, time: 0.571, L1_loss: 0.252676
step:      464, time: 0.581, L1_loss: 0.207859
step:      465, time: 0.563, L1_loss: 0.259385
step:      466, time: 0.542, L1_loss: 0.151299
step:      467, time: 0.522, L1_loss: 0.167348
step:      468, time: 0.538, L1_loss: 0.301784
step:      469, time: 0.534, L1_loss: 0.137359
step:      470, time: 0.537, L1_loss: 0.279025
step:      471, time: 0.534, L1_loss: 0.295909
step:      472, time: 0.521, L1_loss: 0.121825
step:      473, time: 0.525, L1_loss: 0.204674
step:      474, time: 0.517, L1_loss: 0.180620
step:      475, time: 0.528, L1_loss: 0.177464
step:      476, time: 0.549, L1_loss: 0.147424
step:      477, time: 0.545, L1_loss: 0.145700
step:      478, time: 0.534, L1_loss: 0.219465
step:      479, time: 0.567, L1_loss: 0.216982
step:      480, time: 0.533, L1_loss: 0.204569
step:      481, time: 0.498, L1_loss: 0.297893
step:      482, time: 0.520, L1_loss: 0.254873
step:      483, time: 0.542, L1_loss: 0.169424
step:      484, time: 0.557, L1_loss: 0.284272
step:      485, time: 0.561, L1_loss: 0.155119
step:      486, time: 0.518, L1_loss: 0.255244
step:      487, time: 0.564, L1_loss: 0.277699
step:      488, time: 0.468, L1_loss: 0.246019
step:      489, time: 1.225, L1_loss: 0.126108
step:      490, time: 0.477, L1_loss: 0.159052
step:      491, time: 0.494, L1_loss: 0.229696
step:      492, time: 0.510, L1_loss: 0.291042
step:      493, time: 0.473, L1_loss: 0.162582
step:      494, time: 0.575, L1_loss: 0.252115
step:      495, time: 0.528, L1_loss: 0.269959
step:      496, time: 0.535, L1_loss: 0.196164
step:      497, time: 0.521, L1_loss: 0.324992
step:      498, time: 0.530, L1_loss: 0.218688
step:      499, time: 0.504, L1_loss: 0.128123
step:      500, time: 0.468, L1_loss: 0.270085
step:      501, time: 0.464, L1_loss: 0.227008
step:      502, time: 0.486, L1_loss: 0.182130
step:      503, time: 0.535, L1_loss: 0.192917
step:      504, time: 0.531, L1_loss: 0.339382
step:      505, time: 0.496, L1_loss: 0.232844
step:      506, time: 0.531, L1_loss: 0.222694
step:      507, time: 0.487, L1_loss: 0.247748
step:      508, time: 0.557, L1_loss: 0.296722
Finished test GMM, named: gmm_train_new!
