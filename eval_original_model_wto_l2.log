Namespace(batch_size=4, checkpoint='checkpoints/gmm_train_new/gmm_final.pth', data_list='test_pairs.txt', datamode='test', dataroot='/mnt/nas/dataset_share/VITON/data/', display_count=1, fine_height=256, fine_width=192, gpu_ids='', grid_size=5, name='gmm_train_new', radius=5, result_dir='result', shuffle=False, stage='GMM', tensorboard_dir='tensorboard', workers=4)
Start to test stage: GMM, named: gmm_train_new!
initialization method [normal]
initialization method [normal]
step:        1, time: 0.983, L1_loss: 0.180731
step:        2, time: 0.500, L1_loss: 0.256147
step:        3, time: 0.519, L1_loss: 0.228971
step:        4, time: 0.555, L1_loss: 0.216785
step:        5, time: 0.549, L1_loss: 0.182168
step:        6, time: 0.556, L1_loss: 0.228999
step:        7, time: 0.528, L1_loss: 0.208665
step:        8, time: 0.558, L1_loss: 0.146240
step:        9, time: 0.491, L1_loss: 0.221733
step:       10, time: 0.483, L1_loss: 0.218535
step:       11, time: 0.650, L1_loss: 0.149218
step:       12, time: 0.480, L1_loss: 0.176878
step:       13, time: 0.534, L1_loss: 0.218289
step:       14, time: 0.547, L1_loss: 0.171372
step:       15, time: 0.551, L1_loss: 0.224427
step:       16, time: 0.554, L1_loss: 0.167887
step:       17, time: 0.515, L1_loss: 0.262129
step:       18, time: 0.556, L1_loss: 0.209686
step:       19, time: 1.081, L1_loss: 0.149372
step:       20, time: 0.513, L1_loss: 0.272258
step:       21, time: 0.502, L1_loss: 0.193019
step:       22, time: 0.556, L1_loss: 0.178245
step:       23, time: 0.551, L1_loss: 0.245825
step:       24, time: 0.587, L1_loss: 0.218300
step:       25, time: 0.502, L1_loss: 0.192452
step:       26, time: 0.533, L1_loss: 0.173604
step:       27, time: 0.419, L1_loss: 0.239042
step:       28, time: 0.671, L1_loss: 0.193911
step:       29, time: 0.561, L1_loss: 0.136137
step:       30, time: 0.595, L1_loss: 0.266910
step:       31, time: 0.600, L1_loss: 0.223530
step:       32, time: 0.510, L1_loss: 0.112447
step:       33, time: 0.650, L1_loss: 0.182114
step:       34, time: 0.554, L1_loss: 0.175422
step:       35, time: 0.520, L1_loss: 0.271810
step:       36, time: 0.528, L1_loss: 0.137494
step:       37, time: 0.514, L1_loss: 0.167454
step:       38, time: 0.521, L1_loss: 0.351524
step:       39, time: 0.600, L1_loss: 0.216404
step:       40, time: 0.616, L1_loss: 0.114433
step:       41, time: 0.526, L1_loss: 0.143205
step:       42, time: 0.593, L1_loss: 0.149683
step:       43, time: 0.501, L1_loss: 0.198079
step:       44, time: 0.513, L1_loss: 0.249394
step:       45, time: 0.546, L1_loss: 0.182138
step:       46, time: 0.492, L1_loss: 0.350077
step:       47, time: 0.577, L1_loss: 0.175910
step:       48, time: 0.507, L1_loss: 0.322193
step:       49, time: 0.528, L1_loss: 0.210964
step:       50, time: 0.571, L1_loss: 0.304636
step:       51, time: 0.488, L1_loss: 0.220422
step:       52, time: 0.540, L1_loss: 0.148774
step:       53, time: 0.547, L1_loss: 0.176931
step:       54, time: 0.492, L1_loss: 0.145730
step:       55, time: 0.557, L1_loss: 0.217273
step:       56, time: 0.525, L1_loss: 0.209544
step:       57, time: 0.582, L1_loss: 0.281534
step:       58, time: 0.568, L1_loss: 0.266111
step:       59, time: 0.539, L1_loss: 0.246970
step:       60, time: 0.490, L1_loss: 0.275239
step:       61, time: 0.448, L1_loss: 0.340322
step:       62, time: 0.492, L1_loss: 0.217901
step:       63, time: 0.505, L1_loss: 0.174101
step:       64, time: 0.498, L1_loss: 0.197626
step:       65, time: 0.550, L1_loss: 0.156206
step:       66, time: 0.510, L1_loss: 0.157175
step:       67, time: 0.584, L1_loss: 0.184986
step:       68, time: 0.472, L1_loss: 0.127508
step:       69, time: 0.509, L1_loss: 0.279561
step:       70, time: 0.524, L1_loss: 0.181869
step:       71, time: 0.473, L1_loss: 0.186574
step:       72, time: 0.618, L1_loss: 0.268731
step:       73, time: 0.550, L1_loss: 0.207554
step:       74, time: 0.516, L1_loss: 0.270870
step:       75, time: 0.538, L1_loss: 0.182947
step:       76, time: 0.496, L1_loss: 0.157895
step:       77, time: 0.479, L1_loss: 0.157802
step:       78, time: 0.499, L1_loss: 0.167936
step:       79, time: 0.497, L1_loss: 0.218267
step:       80, time: 0.503, L1_loss: 0.209392
step:       81, time: 0.560, L1_loss: 0.221059
step:       82, time: 0.625, L1_loss: 0.199129
step:       83, time: 0.519, L1_loss: 0.216856
step:       84, time: 0.492, L1_loss: 0.220000
step:       85, time: 0.551, L1_loss: 0.211347
step:       86, time: 0.545, L1_loss: 0.263965
step:       87, time: 0.541, L1_loss: 0.180957
step:       88, time: 0.548, L1_loss: 0.114581
step:       89, time: 0.511, L1_loss: 0.192856
step:       90, time: 0.519, L1_loss: 0.179410
step:       91, time: 0.499, L1_loss: 0.161352
step:       92, time: 0.525, L1_loss: 0.237586
step:       93, time: 0.496, L1_loss: 0.241560
step:       94, time: 0.534, L1_loss: 0.158788
step:       95, time: 0.527, L1_loss: 0.180885
step:       96, time: 0.502, L1_loss: 0.285860
step:       97, time: 0.392, L1_loss: 0.201121
step:       98, time: 0.702, L1_loss: 0.314537
step:       99, time: 0.539, L1_loss: 0.115440
step:      100, time: 0.509, L1_loss: 0.295348
step:      101, time: 0.518, L1_loss: 0.238611
step:      102, time: 0.508, L1_loss: 0.167849
step:      103, time: 0.534, L1_loss: 0.269916
step:      104, time: 0.504, L1_loss: 0.223005
step:      105, time: 0.502, L1_loss: 0.205738
step:      106, time: 0.563, L1_loss: 0.283354
step:      107, time: 0.539, L1_loss: 0.238649
step:      108, time: 0.511, L1_loss: 0.173232
step:      109, time: 0.534, L1_loss: 0.252802
step:      110, time: 0.513, L1_loss: 0.240034
step:      111, time: 0.499, L1_loss: 0.161244
step:      112, time: 0.474, L1_loss: 0.162198
step:      113, time: 0.515, L1_loss: 0.172354
step:      114, time: 0.518, L1_loss: 0.208503
step:      115, time: 0.510, L1_loss: 0.166358
step:      116, time: 0.525, L1_loss: 0.154150
step:      117, time: 0.522, L1_loss: 0.240887
step:      118, time: 0.537, L1_loss: 0.206631
step:      119, time: 0.510, L1_loss: 0.163715
step:      120, time: 0.536, L1_loss: 0.176761
step:      121, time: 0.525, L1_loss: 0.115624
step:      122, time: 0.531, L1_loss: 0.195326
step:      123, time: 0.596, L1_loss: 0.228715
step:      124, time: 0.546, L1_loss: 0.236695
step:      125, time: 0.516, L1_loss: 0.160295
step:      126, time: 0.501, L1_loss: 0.205798
step:      127, time: 0.511, L1_loss: 0.336675
step:      128, time: 0.508, L1_loss: 0.342292
step:      129, time: 0.516, L1_loss: 0.134876
step:      130, time: 0.508, L1_loss: 0.254357
step:      131, time: 0.518, L1_loss: 0.216869
step:      132, time: 0.404, L1_loss: 0.244686
step:      133, time: 0.454, L1_loss: 0.232787
step:      134, time: 0.508, L1_loss: 0.228743
step:      135, time: 0.558, L1_loss: 0.154495
step:      136, time: 0.519, L1_loss: 0.295401
step:      137, time: 0.546, L1_loss: 0.230715
step:      138, time: 0.527, L1_loss: 0.167472
step:      139, time: 0.503, L1_loss: 0.239080
step:      140, time: 1.058, L1_loss: 0.276984
step:      141, time: 0.533, L1_loss: 0.080286
step:      142, time: 0.484, L1_loss: 0.253658
step:      143, time: 0.510, L1_loss: 0.317731
step:      144, time: 0.518, L1_loss: 0.211493
step:      145, time: 0.491, L1_loss: 0.195658
step:      146, time: 0.528, L1_loss: 0.189745
step:      147, time: 0.491, L1_loss: 0.237363
step:      148, time: 0.513, L1_loss: 0.183702
step:      149, time: 0.492, L1_loss: 0.309750
step:      150, time: 0.486, L1_loss: 0.163519
step:      151, time: 0.496, L1_loss: 0.158181
step:      152, time: 0.456, L1_loss: 0.240421
step:      153, time: 0.491, L1_loss: 0.250653
step:      154, time: 0.488, L1_loss: 0.156572
step:      155, time: 0.502, L1_loss: 0.227332
step:      156, time: 0.467, L1_loss: 0.176758
step:      157, time: 0.535, L1_loss: 0.198791
step:      158, time: 0.537, L1_loss: 0.195178
step:      159, time: 0.452, L1_loss: 0.147502
step:      160, time: 0.514, L1_loss: 0.256361
step:      161, time: 0.506, L1_loss: 0.136566
step:      162, time: 0.548, L1_loss: 0.236490
step:      163, time: 0.462, L1_loss: 0.120908
step:      164, time: 0.460, L1_loss: 0.149714
step:      165, time: 0.520, L1_loss: 0.265072
step:      166, time: 0.502, L1_loss: 0.256608
step:      167, time: 1.112, L1_loss: 0.198945
step:      168, time: 0.543, L1_loss: 0.187858
step:      169, time: 0.500, L1_loss: 0.263755
step:      170, time: 0.523, L1_loss: 0.189919
step:      171, time: 0.514, L1_loss: 0.338686
step:      172, time: 0.519, L1_loss: 0.241454
step:      173, time: 0.521, L1_loss: 0.128215
step:      174, time: 0.559, L1_loss: 0.208785
step:      175, time: 0.510, L1_loss: 0.249128
step:      176, time: 0.496, L1_loss: 0.175606
step:      177, time: 0.495, L1_loss: 0.186148
step:      178, time: 0.505, L1_loss: 0.206890
step:      179, time: 0.492, L1_loss: 0.186483
step:      180, time: 0.523, L1_loss: 0.206360
step:      181, time: 0.566, L1_loss: 0.224698
step:      182, time: 0.500, L1_loss: 0.166122
step:      183, time: 0.530, L1_loss: 0.188448
step:      184, time: 0.509, L1_loss: 0.189861
step:      185, time: 0.522, L1_loss: 0.254374
step:      186, time: 0.507, L1_loss: 0.133452
step:      187, time: 0.533, L1_loss: 0.096420
step:      188, time: 0.496, L1_loss: 0.174585
step:      189, time: 0.528, L1_loss: 0.186343
step:      190, time: 0.546, L1_loss: 0.217879
step:      191, time: 0.530, L1_loss: 0.185658
step:      192, time: 0.506, L1_loss: 0.115032
step:      193, time: 0.439, L1_loss: 0.166432
step:      194, time: 1.040, L1_loss: 0.308145
step:      195, time: 0.444, L1_loss: 0.156638
step:      196, time: 0.427, L1_loss: 0.201124
step:      197, time: 0.523, L1_loss: 0.329115
step:      198, time: 0.510, L1_loss: 0.212671
step:      199, time: 0.517, L1_loss: 0.234536
step:      200, time: 0.499, L1_loss: 0.156478
step:      201, time: 0.528, L1_loss: 0.183649
step:      202, time: 0.501, L1_loss: 0.210178
step:      203, time: 0.527, L1_loss: 0.326499
step:      204, time: 0.531, L1_loss: 0.263796
step:      205, time: 0.539, L1_loss: 0.254211
step:      206, time: 0.549, L1_loss: 0.245700
step:      207, time: 0.513, L1_loss: 0.295465
step:      208, time: 0.531, L1_loss: 0.220957
step:      209, time: 0.546, L1_loss: 0.168738
step:      210, time: 0.499, L1_loss: 0.250080
step:      211, time: 0.534, L1_loss: 0.219388
step:      212, time: 0.539, L1_loss: 0.242630
step:      213, time: 0.473, L1_loss: 0.274605
step:      214, time: 0.532, L1_loss: 0.142092
step:      215, time: 0.606, L1_loss: 0.215939
step:      216, time: 0.554, L1_loss: 0.213596
step:      217, time: 0.597, L1_loss: 0.244802
step:      218, time: 0.526, L1_loss: 0.310246
step:      219, time: 0.504, L1_loss: 0.185289
step:      220, time: 0.449, L1_loss: 0.289690
step:      221, time: 1.106, L1_loss: 0.175513
step:      222, time: 0.491, L1_loss: 0.146926
step:      223, time: 0.512, L1_loss: 0.233566
step:      224, time: 0.591, L1_loss: 0.221149
step:      225, time: 0.522, L1_loss: 0.190604
step:      226, time: 0.485, L1_loss: 0.143761
step:      227, time: 0.488, L1_loss: 0.242311
step:      228, time: 0.482, L1_loss: 0.188891
step:      229, time: 0.538, L1_loss: 0.099030
step:      230, time: 0.512, L1_loss: 0.165651
step:      231, time: 0.513, L1_loss: 0.232387
step:      232, time: 0.508, L1_loss: 0.268095
step:      233, time: 0.433, L1_loss: 0.225694
step:      234, time: 0.536, L1_loss: 0.238470
step:      235, time: 0.529, L1_loss: 0.098714
step:      236, time: 0.533, L1_loss: 0.235956
step:      237, time: 0.525, L1_loss: 0.259165
step:      238, time: 0.546, L1_loss: 0.209924
step:      239, time: 0.502, L1_loss: 0.192350
step:      240, time: 0.516, L1_loss: 0.191011
step:      241, time: 0.502, L1_loss: 0.154840
step:      242, time: 0.469, L1_loss: 0.202912
step:      243, time: 0.497, L1_loss: 0.148437
step:      244, time: 0.504, L1_loss: 0.222989
step:      245, time: 0.449, L1_loss: 0.192779
step:      246, time: 0.460, L1_loss: 0.198417
step:      247, time: 1.177, L1_loss: 0.329266
step:      248, time: 0.506, L1_loss: 0.231666
step:      249, time: 0.523, L1_loss: 0.279010
step:      250, time: 0.521, L1_loss: 0.211220
step:      251, time: 0.503, L1_loss: 0.181390
step:      252, time: 0.477, L1_loss: 0.225792
step:      253, time: 0.517, L1_loss: 0.334507
step:      254, time: 0.517, L1_loss: 0.225631
step:      255, time: 0.530, L1_loss: 0.136625
step:      256, time: 0.507, L1_loss: 0.184679
step:      257, time: 0.455, L1_loss: 0.188089
step:      258, time: 0.454, L1_loss: 0.137955
step:      259, time: 0.480, L1_loss: 0.184709
step:      260, time: 0.506, L1_loss: 0.175557
step:      261, time: 0.545, L1_loss: 0.153157
step:      262, time: 0.508, L1_loss: 0.106971
step:      263, time: 0.500, L1_loss: 0.134912
step:      264, time: 0.497, L1_loss: 0.250592
step:      265, time: 0.498, L1_loss: 0.232369
step:      266, time: 0.558, L1_loss: 0.209176
step:      267, time: 0.553, L1_loss: 0.222543
step:      268, time: 0.618, L1_loss: 0.223560
step:      269, time: 0.543, L1_loss: 0.209223
step:      270, time: 0.530, L1_loss: 0.237837
step:      271, time: 0.510, L1_loss: 0.279341
step:      272, time: 0.498, L1_loss: 0.103473
step:      273, time: 0.531, L1_loss: 0.219447
step:      274, time: 0.521, L1_loss: 0.203679
step:      275, time: 0.516, L1_loss: 0.234604
step:      276, time: 0.496, L1_loss: 0.184549
step:      277, time: 0.518, L1_loss: 0.153413
step:      278, time: 0.528, L1_loss: 0.185940
step:      279, time: 0.529, L1_loss: 0.094259
step:      280, time: 0.529, L1_loss: 0.194066
step:      281, time: 0.528, L1_loss: 0.110351
step:      282, time: 0.477, L1_loss: 0.201771
step:      283, time: 0.464, L1_loss: 0.255121
step:      284, time: 0.476, L1_loss: 0.171728
step:      285, time: 0.547, L1_loss: 0.275687
step:      286, time: 0.521, L1_loss: 0.116685
step:      287, time: 0.547, L1_loss: 0.202986
step:      288, time: 0.531, L1_loss: 0.238030
step:      289, time: 0.507, L1_loss: 0.132365
step:      290, time: 0.461, L1_loss: 0.255013
step:      291, time: 1.021, L1_loss: 0.215821
step:      292, time: 0.512, L1_loss: 0.198881
step:      293, time: 0.501, L1_loss: 0.179935
step:      294, time: 0.523, L1_loss: 0.239921
step:      295, time: 0.443, L1_loss: 0.123469
step:      296, time: 0.478, L1_loss: 0.163516
step:      297, time: 0.460, L1_loss: 0.285540
step:      298, time: 0.556, L1_loss: 0.240389
step:      299, time: 0.526, L1_loss: 0.233558
step:      300, time: 0.542, L1_loss: 0.215738
step:      301, time: 0.486, L1_loss: 0.202578
step:      302, time: 0.496, L1_loss: 0.220702
step:      303, time: 0.514, L1_loss: 0.094899
step:      304, time: 0.466, L1_loss: 0.138730
step:      305, time: 0.490, L1_loss: 0.195245
step:      306, time: 0.514, L1_loss: 0.175447
step:      307, time: 0.560, L1_loss: 0.154696
step:      308, time: 0.522, L1_loss: 0.246267
step:      309, time: 0.524, L1_loss: 0.216568
step:      310, time: 0.452, L1_loss: 0.254069
step:      311, time: 0.483, L1_loss: 0.235608
step:      312, time: 0.518, L1_loss: 0.156398
step:      313, time: 0.568, L1_loss: 0.243133
step:      314, time: 0.511, L1_loss: 0.329718
step:      315, time: 0.539, L1_loss: 0.244832
step:      316, time: 0.523, L1_loss: 0.207755
step:      317, time: 0.433, L1_loss: 0.148916
step:      318, time: 1.101, L1_loss: 0.242935
step:      319, time: 0.461, L1_loss: 0.254693
step:      320, time: 0.515, L1_loss: 0.249282
step:      321, time: 0.559, L1_loss: 0.331200
step:      322, time: 0.509, L1_loss: 0.185201
step:      323, time: 0.524, L1_loss: 0.243525
step:      324, time: 0.512, L1_loss: 0.107053
step:      325, time: 0.541, L1_loss: 0.130189
step:      326, time: 0.525, L1_loss: 0.227779
step:      327, time: 0.504, L1_loss: 0.187252
step:      328, time: 0.493, L1_loss: 0.241764
step:      329, time: 0.512, L1_loss: 0.134242
step:      330, time: 0.543, L1_loss: 0.255544
step:      331, time: 0.557, L1_loss: 0.259456
step:      332, time: 0.502, L1_loss: 0.105882
step:      333, time: 0.505, L1_loss: 0.169859
step:      334, time: 0.502, L1_loss: 0.178985
step:      335, time: 0.518, L1_loss: 0.198175
step:      336, time: 1.591, L1_loss: 0.240944
step:      337, time: 0.516, L1_loss: 0.223325
step:      338, time: 0.532, L1_loss: 0.262255
step:      339, time: 0.488, L1_loss: 0.248411
step:      340, time: 0.469, L1_loss: 0.222170
step:      341, time: 0.471, L1_loss: 0.267688
step:      342, time: 0.462, L1_loss: 0.237241
step:      343, time: 0.496, L1_loss: 0.200588
step:      344, time: 1.050, L1_loss: 0.198590
step:      345, time: 0.460, L1_loss: 0.272199
step:      346, time: 0.493, L1_loss: 0.175435
step:      347, time: 0.479, L1_loss: 0.126100
step:      348, time: 0.560, L1_loss: 0.345907
step:      349, time: 0.506, L1_loss: 0.203882
step:      350, time: 0.527, L1_loss: 0.243718
step:      351, time: 0.503, L1_loss: 0.303316
step:      352, time: 0.505, L1_loss: 0.278539
step:      353, time: 0.520, L1_loss: 0.221186
step:      354, time: 0.515, L1_loss: 0.285597
step:      355, time: 0.509, L1_loss: 0.214164
step:      356, time: 0.524, L1_loss: 0.207232
step:      357, time: 0.510, L1_loss: 0.151385
step:      358, time: 0.538, L1_loss: 0.246987
step:      359, time: 0.566, L1_loss: 0.325556
step:      360, time: 0.532, L1_loss: 0.201213
step:      361, time: 0.510, L1_loss: 0.198507
step:      362, time: 0.505, L1_loss: 0.136378
step:      363, time: 0.482, L1_loss: 0.222837
step:      364, time: 0.551, L1_loss: 0.176300
step:      365, time: 0.515, L1_loss: 0.170961
step:      366, time: 0.529, L1_loss: 0.241396
step:      367, time: 0.518, L1_loss: 0.188563
step:      368, time: 0.536, L1_loss: 0.180226
step:      369, time: 0.543, L1_loss: 0.239770
step:      370, time: 0.503, L1_loss: 0.297955
step:      371, time: 1.024, L1_loss: 0.295265
step:      372, time: 0.523, L1_loss: 0.187134
step:      373, time: 0.570, L1_loss: 0.216755
step:      374, time: 0.534, L1_loss: 0.180917
step:      375, time: 0.503, L1_loss: 0.154574
step:      376, time: 0.500, L1_loss: 0.173174
step:      377, time: 0.486, L1_loss: 0.094827
step:      378, time: 0.532, L1_loss: 0.191121
step:      379, time: 0.547, L1_loss: 0.106298
step:      380, time: 0.537, L1_loss: 0.181078
step:      381, time: 0.496, L1_loss: 0.277512
step:      382, time: 0.472, L1_loss: 0.206704
step:      383, time: 0.460, L1_loss: 0.213856
step:      384, time: 0.502, L1_loss: 0.253549
step:      385, time: 0.518, L1_loss: 0.221529
step:      386, time: 0.533, L1_loss: 0.142823
step:      387, time: 0.476, L1_loss: 0.104621
step:      388, time: 0.517, L1_loss: 0.445927
step:      389, time: 0.566, L1_loss: 0.280327
step:      390, time: 0.480, L1_loss: 0.115851
step:      391, time: 0.504, L1_loss: 0.161420
step:      392, time: 0.547, L1_loss: 0.266614
step:      393, time: 0.526, L1_loss: 0.185604
step:      394, time: 0.535, L1_loss: 0.174678
step:      395, time: 0.545, L1_loss: 0.212517
step:      396, time: 0.546, L1_loss: 0.171085
step:      397, time: 0.465, L1_loss: 0.187920
step:      398, time: 1.085, L1_loss: 0.225252
step:      399, time: 0.563, L1_loss: 0.185010
step:      400, time: 0.510, L1_loss: 0.178034
step:      401, time: 0.492, L1_loss: 0.159070
step:      402, time: 0.580, L1_loss: 0.219148
step:      403, time: 0.520, L1_loss: 0.260964
step:      404, time: 0.482, L1_loss: 0.207383
step:      405, time: 0.517, L1_loss: 0.244893
step:      406, time: 0.545, L1_loss: 0.192154
step:      407, time: 0.516, L1_loss: 0.152067
step:      408, time: 0.471, L1_loss: 0.143226
step:      409, time: 0.517, L1_loss: 0.208610
step:      410, time: 0.505, L1_loss: 0.212109
step:      411, time: 0.493, L1_loss: 0.224499
step:      412, time: 0.508, L1_loss: 0.220048
step:      413, time: 0.598, L1_loss: 0.193819
step:      414, time: 0.518, L1_loss: 0.273165
step:      415, time: 0.552, L1_loss: 0.275581
step:      416, time: 0.490, L1_loss: 0.133534
step:      417, time: 0.525, L1_loss: 0.134504
step:      418, time: 0.519, L1_loss: 0.176180
step:      419, time: 0.498, L1_loss: 0.261728
step:      420, time: 0.491, L1_loss: 0.207600
step:      421, time: 0.476, L1_loss: 0.226314
step:      422, time: 0.532, L1_loss: 0.290684
step:      423, time: 0.488, L1_loss: 0.238771
step:      424, time: 1.074, L1_loss: 0.196454
step:      425, time: 0.577, L1_loss: 0.154373
step:      426, time: 0.507, L1_loss: 0.195145
step:      427, time: 0.550, L1_loss: 0.232902
step:      428, time: 0.528, L1_loss: 0.156866
step:      429, time: 0.491, L1_loss: 0.131451
step:      430, time: 0.528, L1_loss: 0.214284
step:      431, time: 0.516, L1_loss: 0.219101
step:      432, time: 0.517, L1_loss: 0.193633
step:      433, time: 0.538, L1_loss: 0.285475
step:      434, time: 0.541, L1_loss: 0.154591
step:      435, time: 0.525, L1_loss: 0.177265
step:      436, time: 0.492, L1_loss: 0.219142
step:      437, time: 0.526, L1_loss: 0.266637
step:      438, time: 0.506, L1_loss: 0.208141
step:      439, time: 0.529, L1_loss: 0.346205
step:      440, time: 0.484, L1_loss: 0.143075
step:      441, time: 0.559, L1_loss: 0.182495
step:      442, time: 0.533, L1_loss: 0.248643
step:      443, time: 0.413, L1_loss: 0.165925
step:      444, time: 0.481, L1_loss: 0.161517
step:      445, time: 0.468, L1_loss: 0.180603
step:      446, time: 0.489, L1_loss: 0.289480
step:      447, time: 0.565, L1_loss: 0.165421
step:      448, time: 0.512, L1_loss: 0.296090
step:      449, time: 0.501, L1_loss: 0.119838
step:      450, time: 0.513, L1_loss: 0.185422
step:      451, time: 1.139, L1_loss: 0.260585
step:      452, time: 0.501, L1_loss: 0.200814
step:      453, time: 0.494, L1_loss: 0.402904
step:      454, time: 0.482, L1_loss: 0.270628
step:      455, time: 0.484, L1_loss: 0.207036
step:      456, time: 0.470, L1_loss: 0.270113
step:      457, time: 0.473, L1_loss: 0.273387
step:      458, time: 0.514, L1_loss: 0.214082
step:      459, time: 0.526, L1_loss: 0.240244
step:      460, time: 0.525, L1_loss: 0.154059
step:      461, time: 0.525, L1_loss: 0.171789
step:      462, time: 0.516, L1_loss: 0.086647
step:      463, time: 0.496, L1_loss: 0.245972
step:      464, time: 0.483, L1_loss: 0.188503
step:      465, time: 0.411, L1_loss: 0.176039
step:      466, time: 0.486, L1_loss: 0.167192
step:      467, time: 0.480, L1_loss: 0.111934
step:      468, time: 0.504, L1_loss: 0.185416
step:      469, time: 0.468, L1_loss: 0.160316
step:      470, time: 0.487, L1_loss: 0.170468
step:      471, time: 0.510, L1_loss: 0.250912
step:      472, time: 0.552, L1_loss: 0.165558
step:      473, time: 0.506, L1_loss: 0.172592
step:      474, time: 0.484, L1_loss: 0.269411
step:      475, time: 0.470, L1_loss: 0.194197
step:      476, time: 0.550, L1_loss: 0.258043
step:      477, time: 0.482, L1_loss: 0.155342
step:      478, time: 0.486, L1_loss: 0.134195
step:      479, time: 1.100, L1_loss: 0.134552
step:      480, time: 0.514, L1_loss: 0.255803
step:      481, time: 0.501, L1_loss: 0.270894
step:      482, time: 0.492, L1_loss: 0.211544
step:      483, time: 0.508, L1_loss: 0.214972
step:      484, time: 0.481, L1_loss: 0.156160
step:      485, time: 0.550, L1_loss: 0.201299
step:      486, time: 0.529, L1_loss: 0.320036
step:      487, time: 0.518, L1_loss: 0.251150
step:      488, time: 0.555, L1_loss: 0.113293
step:      489, time: 0.525, L1_loss: 0.373922
step:      490, time: 0.546, L1_loss: 0.124962
step:      491, time: 0.525, L1_loss: 0.232971
step:      492, time: 0.545, L1_loss: 0.176735
step:      493, time: 0.571, L1_loss: 0.259135
step:      494, time: 0.524, L1_loss: 0.100701
step:      495, time: 0.573, L1_loss: 0.241204
step:      496, time: 0.489, L1_loss: 0.124111
step:      497, time: 0.424, L1_loss: 0.151712
step:      498, time: 0.449, L1_loss: 0.070027
step:      499, time: 0.510, L1_loss: 0.167670
step:      500, time: 0.532, L1_loss: 0.155683
step:      501, time: 0.539, L1_loss: 0.216926
step:      502, time: 0.502, L1_loss: 0.214697
step:      503, time: 0.516, L1_loss: 0.262534
step:      504, time: 0.552, L1_loss: 0.243955
step:      505, time: 1.054, L1_loss: 0.275168
step:      506, time: 0.518, L1_loss: 0.168616
step:      507, time: 0.501, L1_loss: 0.284438
step:      508, time: 0.497, L1_loss: 0.130510
Finished test GMM, named: gmm_train_new!
